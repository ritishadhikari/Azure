Analyze images with the Computer Vision service:
    The computer vision service is a cognitive service in Microsoft Azure that provides pre-built 
    computer vision capabilities. 

    The service can analyze images, and return detailed information about an image and the objects 
    it depicts

    To use the Computer Vision Service, you would need to create a resource for it in your Azure 
    Subscription. You can use either of the following resource types:
        - Computer Vision:
            - A specific resource for the computer vision service.
            - Use this resource type if you don't intend to use any other cognitive services, or if 
            you want to track utilization and costs for your computer vision resource separately
        - Cognitive Services:
            - A general cognitive services resource that includes Computer vision along with many other 
            cognitive services; such as Text Analytics, Translator Text, and others.
            - Use this resource type if you plan to use multiple cognitive services and want to simplify
            administration and development 

    Either of the above two service provides two pieces of information:
        - Key for authentication
        - Endpoint providing the HTTP address at which your resources can be accessed

    Offerrings from Computer Vision Service:
        - Describing an Image:
            - Generate Human readable phrase or sentence that can describe what was detected in the image
            - Depending on the image contents, the service may return multiple results, or phrases
            - Each returned images will have an associated confidence score, indicating how confident the
            algorithm is in the supplied description
            - The highest confidence phrases will be listed first
        - Tagging Visual Features:
            - The image descriptions generated by computer vision are based on a set of thousands of 
            recognizable objects, which can be used to suggest tags for the image
            - These tags can be associated with the image as metadata that summarizes attributes of the 
            image
            - Ex:
                - SkyScrapper
                - Tower
        - Detecting Objects:
            - This service can identify common objects
            - It can also return through a bounding box co-ordinates, a set of co-ordinates that
            indicate the top, left, width and height of the object detected
        - Detecting Brands:
            - This service provides the ability to identify commercial brands
            - The service has an existing database of thousands of globally recognized logos from 
            commercial brands of products
            - If a known brand is detected, the service returns a response that contains the brand name, 
            a confidence score (from 0 to 1 indicating how positive the identification is) and a 
            bounding box for where in the image of the detected brand was found
        - Detecting Faces:
            - This service can detect and analyze human faces in an image, including the ability to 
            determine age and a bounding box rectangle for the location of the faces
            - The facial analysis capabilities of the computer service are a subset of those provided 
            by the dedicated Face Service
        - Categorizing an Image:
            - Service that categorize images based on their contents
            - It uses a parent/child heirarchy with a "current" limited set of categories
            - When analyzing an image, detected objects are compared to the existing categories to 
            determine the best way to provide the categorization
        - Detecting Domain Specific Content:
            - Supports two specialized domain models:
                - Celebrities
                - Landmarks
        - Optical Character Recognition:
            - Used for OCR capabilities to detect printed and handwritten text in images
        - Additional Capabilities:
            - Detect Image Types
            - Detect Image Color Schemes
            - Generate Thumbnails: Creating small versions of images
            - Moderate Content

Classify images with the Custom Vision service:
    - Training an effective CNN is a complex task that requires considerable expertise in data 
    science and machine learning
    - Common techniques used to train image classification models have been encapsulated into 
    the Custom Vision Cognitive service in Microsoft Azure, making it easy to train a model
    and publish it as a software service with minimal knowledge of deep learning techniques
    - There are two main tasks for creating an image classification solution with Custom Vision:
        - Use existing images to train the model 
        - Publish the model so that client applications can use it to generate predictions
    - The following types of resources can be used for the Azure Subscription:
        - Custom Vision:
            - A dedicated resource for the custom vision service, which can be training, a prediction, 
            or both resources.
        - Cognitive Services:
            - A general cognitive services resource that includes Custom Vision along with many other 
            cognitive services. 
            - You can use this type of resource for training, prediction, or both.
    - The simplest approach is to use a general Cognitive Services resource for both training and 
    prediction
    - This means you only need to concern yourself with one endpoint (the HTTP address at which your 
    service is hosted) and key (a secret value used by client applications to authenticate themselves).
    - If you choose to create a Custom Vision resource, you will be prompted to choose training, 
    prediction, or both - and it's important to note that if you choose "both", then two resources are 
    created - one for training and one for prediction
    - It's also possible to take a mix-and-match approach in which you use a dedicated Custom 
    Vision resource for training, but deploy your model to a Cognitive Services resource for prediction.
    - For the above to work, the training and prediction resources must be created in the same region.
    - Perform Model Training with:
        - Custom Vision portal
        - Or if you have the necessary coding experience you can use one of the Custom Vision service 
        programming language-specific software development kits (SDKs)
    - Model Training's key consideration is that when using images for classification, is to ensure that 
    you have sufficient images of the objects in question and those images should be of the object 
    from many different angles
    - Model Evaluation happens through:
        - Precision
        - Recall
        - Average Precision (Recall)
    - Once model is evaluates, you can publish the model to the prediction resource.
    - To use model for prediction, client application developers need the following information:
        - Project ID:
            - The unique ID of the Custom Vision project you created to train the model
        - Model name
            - The name you assigned to the model during publishing
        - Prediction endpoint:
            - The HTTP address of the endpoints for the prediction resource to which you published 
            the model (not the training resource).  
        - Prediction key: 
            - The authentication key for the prediction resource to which you published the model
            (not the training resource)

Detect objects in images with the Custom Vision service:
    - Uses of Object Detection:
        - Checking for Building Safety
        - Driving Assistance with Lane Assist Capabilities
        - Detecting Tumors
    - An object detection model is used to identify the individual objects in an image and return 
    the following information:
        - Class of each object identified in the image
        - The probability score of the object classification
        - The coordinates of a bounding box for each object

Detect and analyze faces with the Face service:
    - Face Detection involves identifying regions of an image that contain a human face, typically
        by returning bounding box coordinates that form a rectangle around the face 
    
    - Facial Recognition:
        - It is a further application of facial analysis is to train a machine learning model to 
        identify known individuals from their facial features
        - It involves multiple images of each person you want to recognize to train a model so that it 
        can detect those individuals in new images on which it wasn't trained
    
    - Uses of Face Detection:
        - Security:
            - Smartphones OS for unlocking devices
        - Social Media:
            - Automatically tag known friends in photographs
        - Intelligent Monitoring:
            - Monitoring driver face related tiredness or distraction
        - Advertisements:
            - Analyze face and help direct advertisements to an appropriate demographic audience
        - Missing Persons:
            - Using Public Camera, identify missing person in an image frame
        - Identity Validation:
            - Useful at entry kiosks where an authorized person is permitted
    
    - Microsoft Azure provides multiple cognitive services that can be used to detect and analyze
    faces:
        - Computer Vision:
            - Offers Face Detection and some basic face analysis such as returning the bounding box
            coordinates around an image
        - Video Indexer:
            - Used to detect and identify faces in a Video
        - Face:
            - Offers pre-built algorithms that can detect, recognize and analyze faces
            - It offers the widest range of facial analysis capabilities
    
    - Attributes generated from Face Service:
        - Blur:     
            - How blurred the face is
        - Exposure:
            - UnderExposed or OverExposed and applies to the face in the image and not the overall
            image Exposure
        - Glasses:
            - If the person is wearing Glasses
        - Head pose:
            - The person's orientation in a 3D space
        - Noise:
            - How much noisy and grainy the image of the person is
        - Occlusion:
            - If there may be objects blocking the face in the image
    
    - The Limited Access Policy requires customers to submit an inatake form to access Additional
    Face service capabilities including:
        - The ability to compare faces for similarity
        - The ability to identify individuals in an image
    
    - Azure Resources for Face:
        - Face:
            - Use this specific resource if you do not intend to use any other cognitive services, 
            or if you want to track utilization and costs for face separately
        - Cognitive Service:
            - A general cognitive services resource that includes Computer Vision along with many 
            other cognitive services; such as Custom Vision, Form Recognizer, Language, and others. 
            - Use this service if you plan to use multiple cognitive services and want to simplify 
            administration and development
    
    - Which ever resources we chose to create, it will provide two pieces of information that we will
    need to use it:
        - A key that is used to authenticate client applications
        - An endpoint that provides HTTP address at which your resource can be accessed

Read text with the Computer Vision serviceL
    - The ability for computer systems to process written or printed text is an area of 
    artificial intelligence (AI) where computer vision intersects with Natural Language
    Processing
    - You need computer vision capabilities to "read" the text and then you need natural 
    language processing capabilities to make sense of it
    - The basic foundation of processing printed text is optical character recognition (OCR),
    in which a model can be trained to recognize individual shapes as letters, numerals,
    punctuations, or other elements of text

    - OCR Uses:
        - Note Taking
        - Digitizing Forms, such as medical records or historical documents
        - Scanning printed or handwritten checks for bank deposits
    
    - Azure Read API:
        - Computer Vision
            - A specific resource for the Computer Vision service
            - Use this if you do not intend to use any other cognitive service or if you want 
            to track utilization and costs for your Computer Vision resource separately
        - Cognitive Services: 
            - Use this resource type if you plan to use multiple cognitive services and want to simplify 
            administration and development
        - This service also provides the usual 
            - Key
            - endpoint
        - The Read API service within the computer vision resource, uses the latest recognition 
        models and is optimized for images that have a significant amount of text or has considerable
        visual noise
        - It handles scanned documents that handle that have a lot of text
        - It provides the ability to extract large amounts of typewritten text from images
        - It has the ability to automatically determine the proper recognition model to use, taking
        into consideration lines of text and supporting images with printed text as well as
        recognize handwriting   
        - Since the ReadAPI can work with large documents, it works asyncronously so as not to 
        block application while it is reading the content and returning results to your application
        - For asyncronous read, the application must use a three-step process:
            - Submit an image to the API and retrieve an operation id in response
            - Use the operation ID to check on the status of the image analysis operation and wait
            until it has completed
            - Retrieve the results of the operation   
        - The results from the Read API are arranged into the following heirarchy:
            - Pages:
                - One for each page of text, including information about the page size and 
                orientation
            - Lines:
                - The lines of text on a page
            - Words
                - The words in a line of text, including the bounding box co-ordinates and text
                itself