{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1691471799799
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\r\n",
            "Version: 1.8.0\r\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\r\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\r\n",
            "Author: Microsoft Corporation\r\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\r\n",
            "License: MIT License\r\n",
            "Location: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\r\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\r\n",
            "Required-by: \r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1691471982696
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential=DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    credential=InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1691472015387
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "ml_client=MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1691472153745
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src folder created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "script_folder=\"src\"\n",
        "\n",
        "os.makedirs(name=script_folder, exist_ok=True)\n",
        "print(f\"{script_folder} folder created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/prep-data.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/prep-data.py\n",
        "\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def main(args):\n",
        "    df=get_data(path=args.input_data)\n",
        "    cleaned_data=clean_data(df=df)\n",
        "    normalized_data=normalize_data(df=cleaned_data)\n",
        "    output_df=normalized_data.to_csv(\n",
        "        path_or_buf=Path(args.output_data)/\"diabetes.csv\",\n",
        "        index=False\n",
        "        )\n",
        "\n",
        "def get_data(path):\n",
        "    df=pd.read_csv(path)\n",
        "    row_count=df.shape[0]\n",
        "    print(f\"Preparing {row_count} rows of data\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def clean_data(df):\n",
        "    df=df.dropna()\n",
        "    return df\n",
        "\n",
        "def normalize_data(df):\n",
        "    scaler=MinMaxScaler()\n",
        "    num_cols= ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure',\n",
        "    'TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "\n",
        "    df[num_cols]=scaler.fit_transform(X=df[num_cols])\n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    parser=argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--input_data\", dest=\"input_data\", type=str)\n",
        "    parser.add_argument(\"--output_data\", dest=\"output_data\", type=str)\n",
        "    args=parser.parse_args()\n",
        "    \n",
        "    return args\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    args=parse_args()\n",
        "    main(args=args)\n",
        "    print(\"*\"*60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model.py\n",
        "\n",
        "import mlflow\n",
        "import glob\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    mlflow.autolog()\n",
        "\n",
        "    # read data\n",
        "    df=get_data(data_path=args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test=split_data(df=df)\n",
        "\n",
        "    # train model\n",
        "    model=train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "    eval_model(model=model, X_test=X_test, y_test=y_test)\n",
        "\n",
        "def get_data(data_path):\n",
        "    all_files=glob.glob(pathname=data_path+\"/*.csv\")\n",
        "    df=pd.concat(objs=[pd.read_csv(f) for f in all_files],sort=False)\n",
        "    return df\n",
        "\n",
        "def split_data(df):\n",
        "    num_cols= ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure',\n",
        "    'TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "    X,y=df[num_cols].values, df['Diabetic'].values\n",
        "    return train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(key=\"Regularization Rate\", value=reg_rate)\n",
        "    print(\"Training Model\")\n",
        "    model=LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "    mlflow.sklearn.save_model(model, args.model_output)\n",
        "    return model\n",
        "\n",
        "def eval_model(model, X_test, y_test):\n",
        "    y_hat=model.predict(X_test)\n",
        "    # calculate accuracy\n",
        "    acc=np.average(y_hat==y_test)\n",
        "    print(f\"Accuracy:{acc}\")\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores=model.predict_proba(X_test)\n",
        "    auc=roc_auc_score(y_true=y_test, y_score=y_scores[:,1])\n",
        "    print(f\"AUC: {str(auc)}\")\n",
        "\n",
        "    # Plot ROC Curve\n",
        "    fpr, tpr, thresholds=roc_curve(y_true=y_test, y_score=y_scores[:,1])\n",
        "    fig=plt.figure(figsize=(6,4))\n",
        "    plt.plot([0,1],[0,1],\"k--\")\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "\n",
        "def parse_args():\n",
        "    parser=argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--training_data\", dest=\"training_data\", type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest=\"reg_rate\", type=float, default=0.01)\n",
        "    parser.add_argument(\"--model_output\", dest=\"model_output\", type=str)\n",
        "    args=parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    argument=parse_args()\n",
        "    main(argument)\n",
        "    print(\"*\"*60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<h3> Create YAML for each component you want to run as a Pipeline Setup </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting prep-data.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile prep-data.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: prep_data\n",
        "display_name: Prepare Training Data\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "    input_data:\n",
        "        type: uri_file\n",
        "outputs:\n",
        "    output_data:\n",
        "        type: uri_folder\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "    python prep-data.py\n",
        "    --input_data ${{inputs.input_data}}\n",
        "    --output_data ${{outputs.output_data}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting train-model.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile train-model.yml\n",
        "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
        "name: train_model\n",
        "display_name: Train a Logistic Regression Classifier Model\n",
        "version: 1\n",
        "type: command\n",
        "inputs:\n",
        "    training_data:\n",
        "        type: uri_folder\n",
        "    reg_rate:\n",
        "        type: number\n",
        "        default: 0.01\n",
        "outputs:\n",
        "    model_output:\n",
        "        type: mlflow_model\n",
        "code: ./src\n",
        "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
        "command: >-\n",
        "    python train-model.py\n",
        "    --training_data ${{inputs.training_data}}\n",
        "    --reg_rate ${{inputs.reg_rate}}\n",
        "    --model_output ${{outputs.model_output}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<h3>  Load the Components </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1691480733279
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import load_component\n",
        "parent_dir=\"\"\n",
        "\n",
        "prep_data=load_component(source=parent_dir+\"./prep-data.yml\")\n",
        "train_logistic_regression=load_component(source=parent_dir+\"./train-model.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<h3> Build The Pipeline</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1691480737244
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "\n",
        "@pipeline()\n",
        "def diabetes_classification(pipeline_job_input):\n",
        "    prepared_data=prep_data(input_data=pipeline_job_input)  # the source file / output from darastore\n",
        "    trained_model=train_logistic_regression(training_data=prepared_data.outputs.output_data)  # output from preparation stage\n",
        "\n",
        "    return {\n",
        "        \"pipeline_job_transformed_data\":prepared_data.outputs.output_data,  # output from preparation stage\n",
        "        \"pipeline_job_trained_model\": trained_model.outputs.model_output  # output from train model stage\n",
        "    }\n",
        "\n",
        "pipeline_job=diabetes_classification(pipeline_job_input=Input(\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    path=\"azureml:diabetes-data:1\"\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1691480739175
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "display_name: diabetes_classification\n",
            "type: pipeline\n",
            "inputs:\n",
            "  pipeline_job_input:\n",
            "    type: uri_file\n",
            "    path: azureml:diabetes-data:1\n",
            "outputs:\n",
            "  pipeline_job_transformed_data:\n",
            "    type: uri_folder\n",
            "  pipeline_job_trained_model:\n",
            "    type: mlflow_model\n",
            "jobs:\n",
            "  prepared_data:\n",
            "    type: command\n",
            "    inputs:\n",
            "      input_data:\n",
            "        path: ${{parent.inputs.pipeline_job_input}}\n",
            "    outputs:\n",
            "      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: prep_data\n",
            "      version: '1'\n",
            "      display_name: Prepare Training Data\n",
            "      type: command\n",
            "      inputs:\n",
            "        input_data:\n",
            "          type: uri_file\n",
            "      outputs:\n",
            "        output_data:\n",
            "          type: uri_folder\n",
            "      command: python prep-data.py --input_data ${{inputs.input_data}} --output_data\n",
            "        ${{outputs.output_data}}\n",
            "      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/cib638a26176bc414592/code/Users/ritishadhikari/azure-ml-labs/Labs/09/src\n",
            "      is_deterministic: true\n",
            "  trained_model:\n",
            "    type: command\n",
            "    inputs:\n",
            "      training_data:\n",
            "        path: ${{parent.jobs.prepared_data.outputs.output_data}}\n",
            "    outputs:\n",
            "      model_output: ${{parent.outputs.pipeline_job_trained_model}}\n",
            "    component:\n",
            "      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
            "      name: train_model\n",
            "      version: '1'\n",
            "      display_name: Train a Logistic Regression Classifier Model\n",
            "      type: command\n",
            "      inputs:\n",
            "        training_data:\n",
            "          type: uri_folder\n",
            "        reg_rate:\n",
            "          type: number\n",
            "          default: '0.01'\n",
            "      outputs:\n",
            "        model_output:\n",
            "          type: mlflow_model\n",
            "      command: python train-model.py --training_data ${{inputs.training_data}} --reg_rate\n",
            "        ${{inputs.reg_rate}} --model_output ${{outputs.model_output}}\n",
            "      environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
            "      code: /mnt/batch/tasks/shared/LS_root/mounts/clusters/cib638a26176bc414592/code/Users/ritishadhikari/azure-ml-labs/Labs/09/src\n",
            "      is_deterministic: true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the configuration of the pipeline job\n",
        "print(pipeline_job)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1691480743296
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# change output mode\n",
        "pipeline_job.outputs.pipeline_job_transformed_data.mode=\"upload\"\n",
        "pipeline_job.outputs.pipeline_job_trained_model.mode=\"upload\"\n",
        "\n",
        "# pipeline level compute\n",
        "pipeline_job.settings.default_compute=\"aml-cluster\"\n",
        "\n",
        "# pipeline level datastore\n",
        "pipeline_job.settings.default_datastore=\"workspaceblobstore\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<h3> Submit Pipeline Job </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1691480750309
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading src (0.0 MBs):   0%|          | 0/3923 [00:00<?, ?it/s]\r\u001b[32mUploading src (0.0 MBs): 100%|██████████| 3923/3923 [00:00<00:00, 39500.51it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor Pipeline Job: https://ml.azure.com/runs/sleepy_egg_xsc2kkl7w1?wsid=/subscriptions/18a1f27f-edf5-495e-9acb-753c93335294/resourcegroups/rg-dp100-lb638a26176bc414592/workspaces/mlw-dp100-lb638a26176bc414592&tid=6a1d2f96-8cdf-4d1a-943d-7b73f4dfbb6d\n"
          ]
        }
      ],
      "source": [
        "pipeline_job=ml_client.jobs.create_or_update(\n",
        "    job=pipeline_job, \n",
        "    experiment_name=\"pipeline diabetes\"\n",
        "    )\n",
        "\n",
        "print( f\"Monitor Pipeline Job: {pipeline_job.studio_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
