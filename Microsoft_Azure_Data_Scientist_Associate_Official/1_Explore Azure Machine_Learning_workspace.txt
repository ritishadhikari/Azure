Explore Azure Machine Learning workspace resources and assets:
    -  Azure Machine Learning provides a platform for data scientists to train, deploy 
    and manage their machine learning models on the Microsoft Azure platform
    - It provides a comprehensive set of resources and assets to train and deploy
    effective ML models
    - To use these resources and assets, you create Azure Machine Learning workspace
    resource in your Azure Subscription
    - In this workspace, you can manage data, compute resources, models, endpoints, 
    and other artifacts related to your machine learning workloads
    
    - As a part of Azure ML Workspace, the following are provided:
        - Azure Storage Account:
            - To store files and notebooks used in the workspace and to store metadata
            of jobs and models
        - Azure Key Vault:
            - To securely manage secrets such as authentication keys and credentials used by The
            workspace
        - Application Insights:
            - To monitor predictive services in the workspace
        - Azure Container Registry:
            - Created when needed to store images for Azure Machine Learning environments
    
    Create Azure ML Workspace using:
        - Azure Portal  
        - Azure Resource Manager Template (ARM)
        - Azure Command Line Interface (CLI)
        - Azure ML Python SDK
    
    Access is granted in Azure using Role Based access control (RBAC) with three built in roles that
    you can use across resources and resource groups to assign permission to users:
        - Owner:
            - Gets full access to the resource and can grant access to others using access control
        - Contributor:
            - Gets full access to all resources, but can't grant access to others
        - Reader:
            - Can only view the resource, but isn't allowed to make any changes
    
    Additional specific built-in roles:
        - AzureML Data Scientist:
            - Can perform all actions within the workspace, except for creating or deleting compute
            resources or editing the workspace settings
        - AzureML Compute Operator:
            - Is allowed to create, change and manage access the compute resources within a workspace

    
    To fully customize permissions, we create a custom role

    Azure Machine Learning Resource:
        - The Workspace
        - Compute resources:
            - Compute Cluster
            - Inference Cluster
            - Attached Compute
            - Compute Instance
        - DataStores:  
            - All data is stored in DataStores which are references to Azure Data Services
    
    Azure Machine Learning Assets:
        - Models:
            - Train ML models with frameworks like Sklearn, Pytorch, etc
            - Common ways to store a model is with pkl
        - Environments:
            - Specify Software packages, environment variables and software settings to run scripts
            - Environment is stored as an image in the Azure Container Registry created with the 
            workspace when it's used for the first time
        - Data:
            - As Data Assets
            - Name and Version your Data Assets
        = Components:
            - Make it easier to share code with a component in a workspace

    Authoring of ML can be done with:
        - Designer
        - Automated ML
        - Notebooks
            - Run a script as a job in Azure Machine Learning
            - When you submit a job to the workspace, all inputs and outputs will be stored in the workspace
            - There are three types of jobs:
                - Command: 
                    - Execute a single script
                - Sweep:
                    - Perform Hyperparameter tuning when executing a single script
                - Pipeline:
                    - Run a pipeline consisting of multiple scripts or components 

    Azure Machine Learning Workspace:   
        - The workspace is a central place where you can work with all resources and assets available
        to train and deploy machine learning models
        - For reproducibiity, the workspace stores a history of all training jobs, including logs, 
        metrics, outputs, and a snapshot of your code
        - A Machine Learning Service is required to create a workspace
        - When a workspace is created, Azure will automatically create other Azure resources 
        within the same resource group to support the workspace
        - You can create Azure ML workspace using:
            - Azure Portal  
            - Azure ARM template
            - Azure CLI with Azure Machine Learning CLI extension
            - Azure Machine Learning Python SDK
        - The Azure Machine Learning Studio is a web portal and provides an easy to use interface
        to create, manage and use resources and assets in the workspace
        - From the Azure Portal, you can also give others access to the Azure Machine Learning 
        Workspace, using Access Control as individual users or teams
        - Initially, you may work with one workspace; however when working on large-scale projects, 
        you may choose to use multiple workspace
        - You can use workspace to group machine learning assets based on projects, deployment 
        environments (for example, test and production), teams or some other organizing principle
        - Link on organizing and setting up Azure ML environments
    
    - Ideally you would want someone like an administrator to create and manage the resources:
        - The Workspace:
            - Train and Track Models
            - Deploy the models to the endpoint
            - Stores all the logs, metrics, outputs and snapshots of your code
        - Compute resources:
            - There are four types of compute in the Azure Machine Learning Workspace:
                - Compute Instances:
                    - Development workstations that data scientists can use to work with data and models
                - Compute Clusters:
                    - Scalable Clusters of VMs for On Demand processing of experiment code
                    - Ideal to use for production workloads as they automatically scale to your needs
                - Inference Clusters:
                    - Deployment targets for predictive services that use your trained models
                - Attached Compute:
                    - Links to existing Azure compute resources, such as Virtual Machines or Azure Data
                    Bricks clusters
            - Best practice is to only allow administrators to create and manage compute resources
            - Data scientists should not be allowed to edit compute, but only use the available compute to
            run their workloads
        - Datastores:
            - The workspace does not store any data itself
            - All data is stored in datastores, which are references to Azure Data Services
            - The connection information to a data service that a datastore represents is stored in the 
            Azure Key Vault
            - When a workspace is created, an Azure Storage account is created and automatically connected 
            to the workspace
            - As a result, two data stores are already added to the workspace:
                - workspacefilestore:
                    - Connects to the file share of the Azure Storage account created with the workspace
                    - Used to store files like Jupyter Notebook and Python scripts
                - workspaceblobstore
                    - Connects to the blob storage of the Azure Storage account created with the workspace
                    - Used to store metrics and output when tracking model training
            - Additionally you can also create datastores to connect to other Azure data services like 
            Azure Storage Accounts or Azure Data Lake Storage (Gen2)
    
    - Assets are created and used at various stages of a project and includes:
        - Models:
            - Common way to store ML models is to package the model as a python pickle file (.pkl extension)
            - Alternatively, you can use the open-source platform MLFlow to store your model in the MLModel
            format
            - To persist models, you can create or register a model in the workspace
            - While creating, specify name and version of the model
            - Versioning allows you to track the specific model you want to use
        - Environments:
            - When you write code that uses any frameworks or libraries, you will need to ensure the 
            necessary components are installed on the compute that will execute the code
            - To list all necessary requirements, you can create environments specifying name and version
            - Environments specify software packages, environment variables and software settings to run
            script
            - An environment is stored as an image in the Azure Container Registry created with the workspace
            when it's used for the first time
            - Whenever you run your script, you can specify the environment that needs to be used by the 
            compute target
            - The environment will install all necessary requirements on the compute before executing the
            script, making your code robust and reusable across compute targets
        - Data:
            - Data Assets refer to a specific file or folder
            - Use data assets to easily access data every time, without having to provide authentication
            every time you want to access it
            - When you create a data asset in the workspace, you will need to point to the file or 
            folder, and the name and version
        - Components:
            - To train ML models, we would need to write code
            - Across projects, there may be code you can reuse
            - Instead of writing code from scratch, you will want to reuse snippets of code from other
            projects
            - Component make it easier to share code in a workspace
            - To create a component, you have to specify the name, version, code and environment needed 
            to run the code 
            - You can use components when creating pipelines    
            - Ex. Normalize Data, Train Regression Model, test the trained model on a validation dataset
    
    - To train models with the Azure Machine Learning Workspace, you can:
        - Use the designer in the Azure Machine Learning Studio:
            - It is ideal for easy and quick exploration during the initial phase of training machine learning
            models
            - Use designer to swiftly create pipelines using components you have created and registered in 
            the workspace
        - Use Automated Machine Learning:
            - Experiment with various algorithms and hyperparameter values
            - It iterates through algorithms paired with feature selections to find the best performing 
            model for your data
        - Run a Jupyter Notebook:
            - All the files you clone or create in the notebooks section are stored in the file share of the 
            Azure Storage account created with the workspace
            - To run notebooks, you will use a compute instance as they are ideal for development and work 
            similar to a virtual machine
            - You can chose to edit and run notebooks in Visual Studio Code, while still using a compute 
            instance to run the notebooks
        - Run a script as a Job
            - Use Scripts to run production ready code
            - You can easily automate the execution of scripts to automate any machine learning workspace
            - Run a script as a job in Azure Machine Learning
            - When you submit a job to the workspace, all inputs and outputs will be stored in the workspace

Explore developer tools for workspace interaction:
    - There are two ways to access the Azure Machine Learning Studio:
        - Launch the studio from the Overview page in the Azure Portal
        - Navigate to the studio directly by signing in at https://ml.azure.com
    
    - Python SDK:
        - It is ideal tool for data scientists that can be used in any python environments
        - Python SDK V2 in Machine Learning studio by default supports Python version 3.10
        - Necessary parameters for authentication:
            - subscription_id
            - resource_group
            - workspace_name


    - Install the Python SDK:
        pip install azure-ai-ml
    
    - Define Authentication
        from azure.ai.ml import MLClient
        from azure.identity import DefaultAzureCredential

        ml_client=MLClient(
            DefaultAzureCredential(), 
            subscription_id, 
            resource_group, 
            workspace
        )
    
    - Connect to the workspace when you create a new job to train a model:
        # configure the Job
        job=command(
            code="./src",
            command="python train.py",
            environment="AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest",
            compute="aml-cluster",
            experiment_name="train-model"
        )
        # connect to workspace and submit job 
        returned_job=ml_client.create_or_update(job)
    
    - Reference Documentation for Python SDK:
        - https://shorturl.at/lstvZ
        - You will find all possible classes, methods and parameters available within the Python SDK
        which can be used to connect and interact
        - Includes a list of classes for all entities you can interact with, for ex. separate classes
        exists when you want to create a datastore that links to an Azure Blob Storage, or to an 
        Azure Data Lake Gen 2   


    - Azure CLI:
        - You can install Azure CLI on a Linux, Mac or windows computer
        - You run commands or scripts to manage Azure resources
        - You can also use the Azure CLI from a browser through the Azure Cloud Shell
        - Check for list of commands available with Azure ML Extension:
            - az ml -h
        - Command to create a compute target:
            - az ml compute create --name aml-cluster --size STANDARD_DS3_V2 \
            --min_instances 0 --max-instances 5  --type AmlCompute \
            --resource-group my-resource-group --workspace-name my-workspace
        - You may prefer using yaml files to define the configuration instead as it becomes
        easier to organize and automate tasks
        - Command to create a compute target with the yaml file (compute.yml)
            - az ml compute create --file compute.yml \
            --resource-group my-resource-group --workspace-name my-workspace
        
    - Advantages of using the Azure CLI with Azure Machine Learning. It allows you to:
        - Automate the creation and configuration of assets and resources to make it repeatable
        - Ensure Consistency for assets and resources that must be replicated in multiple environments
        - Incorporate ML asset configuration into developer operations (DevOps) workflows, such as
        CI/CD Pipelines
        - Recommended for Model retraining with new data

    
    - Use Azure ML studio:
        - When you want to use a no-code approach
        - When you are exploring and you quickly want to review your work
        - If you want to verify that your pipeline ran successfully or what error messages were raised
        if the pipeline failed
    
